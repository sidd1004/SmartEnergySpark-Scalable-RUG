appliance.testing.data = "src/main/resources/data/Home_data.csv"
appliance.testing.data = ${?TESTING_DATA_HOME}
spark.master = "local[*]"
algorithm.type = "knn"
algorithm.type = ${?ALGORITHM_TYPE}
cassandra.datagen {
  hosts = "192.168.99.102"
  hosts = ${?CASSANDRA_DATAGEN_HOSTS}
  port = 30441
  port = ${?CASSANDRA_DATAGEN_PORT}
  keyspace = "applicationlifecycle"
  keyspace = ${?CASSANDRA_DATAGEN_KEYSPACE}
  replication = 1
  replication = ${?CASSANDRA_DATAGEN_KEYSPACE_REPLICATION}
  table_name = "training"
  table_name = ${?CASSANDRA_DATAGEN_TABLE_NAME}
  table {
    schema = "prosumerID text PRIMARY KEY, values text"
    schema = "{?CASSANDRA_DATAGEN_TABLE_SCHEMA}"
  }
}

kafka {
  url = "my-cluster-kafka-bootstrap:9092"
  url = ${?KAFKA_URL}
  topic = "testtopic"
  topic = ${?KAFKA_TOPIC}
  group.id = "wacc"
  group.id = ${?KAFKA_GROUP_ID}
  value.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
  value.deserializer = ${?KAFKA_VALUE_DESERIALIZER}
  key.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
  key.deserializer = ${?KAFKA_KEY_DESERIALIZER}
  application.id = "wacc_kafka_streaming"
  application.id = ${?APPLICATION_ID}
  consumer.timeout = 3000
  consumer.timeout = ${?KAFKA_CONSUMER_TIMEOUT}
  streamquery {
    topic = "StreamPipeline"
    startingOffset = "latest"
    checkpointLocation = "/opt/spark/checkpoints/"
  }
  batchquery {
    topic = "BatchPipeline"
    startingOffset = "latest"
    checkpointLocation = "/opt/spark/checkpoints/"
  }
}
